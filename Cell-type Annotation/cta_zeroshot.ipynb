{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import matplotlib\n",
    "import mygene\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import sklearn\n",
    "import random\n",
    "import scanpy as sc\n",
    "# import sentence_transformers\n",
    "plt.style.use('ggplot')\n",
    "#plt.style.use('seaborn-v0_8-dark-palette')\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Helvetica\"\n",
    "})\n",
    "import matplotlib_inline\n",
    "import time\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "np.random.seed(202310)\n",
    "# use hnswlib for NN classification\n",
    "try:\n",
    "    import hnswlib\n",
    "    hnswlib_imported = True\n",
    "except ImportError:\n",
    "    hnswlib_imported = False\n",
    "    print(\"hnswlib not installed! We highly recommend installing it for fast similarity search.\")\n",
    "    print(\"To install it, run: pip install hnswlib\")\n",
    "from scipy.stats import mode\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train = sc.read(\"/gpfs/gibbs/pi/zhao/tl688/deconvdatasets/demo_train.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/gpfs/gibbs/pi/zhao/tl688/GenePT/data_embedding/GPT_3_5_gene_embeddings.pickle\", \"rb\") as fp:\n",
    "    GPT_3_5_gene_embeddings = pickle.load(fp)\n",
    "gene_names= list(adata_train.var.index)\n",
    "count_missing = 0\n",
    "EMBED_DIM = 1536 # embedding dim from GPT-3.5\n",
    "lookup_embed = np.zeros(shape=(len(gene_names),EMBED_DIM))\n",
    "for i, gene in enumerate(gene_names):\n",
    "    if gene in GPT_3_5_gene_embeddings:\n",
    "        lookup_embed[i,:] = GPT_3_5_gene_embeddings[gene].flatten()\n",
    "    else:\n",
    "        count_missing+=1\n",
    "genePT_w_emebed = np.dot(adata_train.X,lookup_embed)/len(gene_names)\n",
    "print(f\"Unable to match {count_missing} out of {len(gene_names)} genes in the GenePT-w embedding\")\n",
    "genePT_w_emebed_train = genePT_w_emebed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_test = sc.read(\"/gpfs/gibbs/pi/zhao/tl688/deconvdatasets/demo_test.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/gpfs/gibbs/pi/zhao/tl688/GenePT/data_embedding/GPT_3_5_gene_embeddings.pickle\", \"rb\") as fp:\n",
    "    GPT_3_5_gene_embeddings = pickle.load(fp)\n",
    "gene_names= list(adata_test.var.index)\n",
    "count_missing = 0\n",
    "EMBED_DIM = 1536 # embedding dim from GPT-3.5\n",
    "lookup_embed = np.zeros(shape=(len(gene_names),EMBED_DIM))\n",
    "for i, gene in enumerate(gene_names):\n",
    "    if gene in GPT_3_5_gene_embeddings:\n",
    "        lookup_embed[i,:] = GPT_3_5_gene_embeddings[gene].flatten()\n",
    "    else:\n",
    "        count_missing+=1\n",
    "# genePT_w_emebed = np.dot(adata_test.X,lookup_embed)/len(gene_names)\n",
    "print(f\"Unable to match {count_missing} out of {len(gene_names)} genes in the GenePT-w embedding\")\n",
    "\n",
    "genePT_w_emebed_test = genePT_w_emebed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = adata_train.obs.Celltype\n",
    "y_test = adata_test.obs.Celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell type clustering\n",
    "# very quick test\n",
    "k = 10  # number of neighbors\n",
    "ref_cell_embeddings = genePT_w_emebed_train\n",
    "test_emebd = genePT_w_emebed_test\n",
    "neighbors_list_gpt_v2 = []\n",
    "if hnswlib_imported:\n",
    "    # Declaring index, using most of the default parameters from https://github.com/nmslib/hnswlib\n",
    "    p = hnswlib.Index(space = 'cosine', dim = ref_cell_embeddings.shape[1]) # possible options are l2, cosine or ip\n",
    "    p.init_index(max_elements = ref_cell_embeddings.shape[0], ef_construction = 200, M = 16)\n",
    "\n",
    "    # Element insertion (can be called several times):\n",
    "    p.add_items(ref_cell_embeddings, ids = np.arange(ref_cell_embeddings.shape[0]))\n",
    "\n",
    "    # Controlling the recall by setting ef:\n",
    "    p.set_ef(50) # ef should always be > k\n",
    "\n",
    "    # Query dataset, k - number of closest elements (returns 2 numpy arrays)\n",
    "    labels, distances = p.knn_query(test_emebd, k = k)\n",
    "\n",
    "idx_list=[i for i in range(test_emebd.shape[0])]\n",
    "gt_list = []\n",
    "pred_list = []\n",
    "for k in idx_list:\n",
    "    # this is the true cell type\n",
    "    gt = y_test[k]\n",
    "    if hnswlib_imported:\n",
    "        idx = labels[k]\n",
    "    else:\n",
    "        idx, sim = get_similar_vectors(test_emebd[k][np.newaxis, ...], ref_cell_embeddings)\n",
    "    pred = mode(y_train[idx], axis=0)\n",
    "    neighbors_list_gpt_v2.append(y_train[idx])\n",
    "    gt_list.append(gt)\n",
    "    pred_list.append(pred[0][0])\n",
    "print(\"Accuracy\", sklearn.metrics.accuracy_score(gt_list, pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Precision, Recall, F1 (Marco weighted) for GenePT-w embedding: ', \\\n",
    "      sklearn.metrics.precision_recall_fscore_support(gt_list, pred_list,average='macro'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
