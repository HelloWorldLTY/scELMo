{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import matplotlib\n",
    "import mygene\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import sklearn\n",
    "import random\n",
    "import scanpy as sc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from xgboost import XGBClassifier\n",
    "# import sentence_transformers\n",
    "plt.style.use('ggplot')\n",
    "#plt.style.use('seaborn-v0_8-dark-palette')\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": False,\n",
    "#     \"font.family\": \"Helvetica\"\n",
    "# })\n",
    "import matplotlib_inline\n",
    "import scib_metrics\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "import openai\n",
    "# remember to set your open AI API key!\n",
    "openai.api_key = '' #replace it with your own API\n",
    "np.random.seed(202310)\n",
    "# use hnswlib for NN classification\n",
    "try:\n",
    "    import hnswlib\n",
    "    hnswlib_imported = True\n",
    "except ImportError:\n",
    "    hnswlib_imported = False\n",
    "    print(\"hnswlib not installed! We highly recommend installing it for fast similarity search.\")\n",
    "    print(\"To install it, run: pip install hnswlib\")\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we consider steps to read different datasets.\n",
    "\n",
    "# adata = sc.read(\"/gpfs/gibbs/pi/zhao/tl688/deconvdatasets/demo_train.h5ad\")\n",
    "\n",
    "# adata = sc.read(\"/gpfs/gibbs/pi/zhao/tl688/deconvdatasets/demo_test.h5ad\")\n",
    "\n",
    "# sampled_adata = sc.read_h5ad(\"../sample_aorta_data_updated.h5ad\")\n",
    "# sampled_adata = sampled_adata[np.where(sampled_adata.obs.celltype!='Unknown')[0]]\n",
    "# adata = sampled_adata.copy()\n",
    "# adata.obs['Celltype'] = adata.obs['celltype'].copy()\n",
    "\n",
    "adata = sc.read(\"/gpfs/gibbs/pi/zhao/wl545/pbmc/datasets/3k_test.h5ad\")\n",
    "adata.obs['Celltype'] = adata.obs['label'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_nmi_ari(adata, label = 'scClassify', key='X_gpt3.5'):\n",
    "    labels = np.array(list(adata.obs[label]))\n",
    "    result1 = scib_metrics.nmi_ari_cluster_labels_leiden(adata.obsp['connectivities'], labels = labels, n_jobs = -1)\n",
    "    result2 = scib_metrics.silhouette_label(adata.obsm[key], labels = labels, rescale=True, chunk_size=256)\n",
    "    print(result1)\n",
    "    print(result2)\n",
    "    return result1, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/gpfs/gibbs/pi/zhao/tl688/cpsc_finalproject/genept_data/GenePT/ensem_emb_gpt3.5all.pickle\", \"rb\") as fp:\n",
    "    GPT_3_5_gene_embeddings = pickle.load(fp)\n",
    "gene_names= list(adata.var.index)\n",
    "count_missing = 0\n",
    "EMBED_DIM = 1536 # embedding dim from GPT-3.5\n",
    "lookup_embed_genept = np.zeros(shape=(len(gene_names),EMBED_DIM))\n",
    "for i, gene in enumerate(gene_names):\n",
    "    if gene in GPT_3_5_gene_embeddings:\n",
    "        lookup_embed_genept[i,:] = GPT_3_5_gene_embeddings[gene].flatten()\n",
    "    else:\n",
    "        count_missing+=1\n",
    "        \n",
    "with open(\"/gpfs/gibbs/pi/zhao/tl688/GenePT/data_embedding/GPT_3_5_gene_embeddings.pickle\", \"rb\") as fp:\n",
    "    GPT_3_5_gene_embeddings = pickle.load(fp)\n",
    "gene_names= list(adata.var.index)\n",
    "count_missing = 0\n",
    "EMBED_DIM = 1536 # embedding dim from GPT-3.5\n",
    "lookup_embed_gpt35 = np.zeros(shape=(len(gene_names),EMBED_DIM))\n",
    "for i, gene in enumerate(gene_names):\n",
    "    if gene in GPT_3_5_gene_embeddings:\n",
    "        lookup_embed_gpt35[i,:] = GPT_3_5_gene_embeddings[gene].flatten()\n",
    "    else:\n",
    "        count_missing+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have different settings for embeddings\n",
    "\n",
    "genePT_w_emebed =  (adata.X @ lookup_embed_genept) /len(gene_names) # GenePTWW\n",
    "\n",
    "genePT_w_emebed = (adata.X @ lookup_embed_gpt35) /len(gene_names) # GPT 3.5 aa\n",
    "\n",
    "genePT_w_emebed = adata.X / np.sum(adata.X, axis=1) [:,None]  @ lookup_embed_gpt35 # GPT 3.5 wa\n",
    "\n",
    "\n",
    "lookup_embed = lookup_embed_genept + lookup_embed_gpt35 \n",
    "genePT_w_emebed = adata.X / np.sum(adata.X, axis=1) [:,None]  @ lookup_embed # GenePT + GPT 3.5 wa\n",
    "\n",
    "lookup_embed = np.concatenate([lookup_embed_genept, lookup_embed_gpt35], axis=1)\n",
    "genePT_w_emebed = adata.X / np.sum(adata.X, axis=1) [:,None]  @ lookup_embed # GenePT || GPT 3.5 wa\n",
    "\n",
    "print(f\"Unable to match {count_missing} out of {len(gene_names)} genes in the GenePT-w embedding\")\n",
    "genePT_w_emebed_test = genePT_w_emebed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cell type, considering aggregration embeddings\n",
    "with open('ensem_emb_celltype.pickle', 'rb') as f:\n",
    "    ct_name_getembedding = pickle.load(f)\n",
    "\n",
    "lookup_embed_ct = np.zeros(shape=(len(adata),EMBED_DIM))\n",
    "for i, gene in enumerate(adata.obs_names):\n",
    "    lookup_embed_ct[i,:] = ct_name_getembedding[adata[gene].obs.Celltype.values[0]]\n",
    "\n",
    "genePT_w_emebed_test += lookup_embed_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PCA, we follow the pipeline from scanpy\n",
    "sc.pp.scale(adata)\n",
    "sc.tl.pca(adata)\n",
    "genePT_w_emebed_test = adata.obsm['X_pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_gpt3.5'] = genePT_w_emebed_test \n",
    "sc.pp.neighbors(adata, use_rep='X_gpt3.5')\n",
    "evaluate_nmi_ari(adata, label = 'Celltype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color='Celltype')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
